{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF计算模型-计算图\n",
    "\n",
    "#### 计算图的概念\n",
    "\n",
    "TF中**每一个计算是计算图上的一个节点**，节点之间描述计算之间的依赖关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 计算图的使用\n",
    "\n",
    "计算图的使用分为两个阶段：**定义计算**（定义计算图中的所有计算）、**执行计算**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "g1 = tf.Graph()         # 生成新的计算图；不同计算图上的张量和运算都不会共享\n",
    "with g1.as_default():\n",
    "    v = tf.get_variable(\"v\", [1,2], initializer = tf.zeros_initializer()) # 设置初始值为0\n",
    "\n",
    "g2 = tf.Graph()\n",
    "with g2.as_default():\n",
    "    v = tf.get_variable(\"v\", [2,1], initializer = tf.ones_initializer())  # 设置初始值为1\n",
    "    \n",
    "with tf.Session(graph = g1) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    with tf.variable_scope(\"\", reuse=True):\n",
    "        sess.run(tf.get_variable(\"v\"))\n",
    "\n",
    "with tf.Session(graph = g2) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    with tf.variable_scope(\"\", reuse=True):\n",
    "        sess.run(tf.get_variable(\"v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.graph is tf.get_default_graph()  # v.graph 获取张量、变量所属的计算图。 tf.get_default_graph() 获取默认计算图\n",
    "g1 is tf.get_default_graph()\n",
    "with g1.device('/gpu:0'):           # 通过计算图指定运行计算的设备\n",
    "    result = a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 计算图中，可以通过集合（collection）来管理不同类别的资源。\n",
    "* 通过tf.add_to_collection()可以将资源加入集合。\n",
    "* 通过tf.get_collection()获取一个集合里面的所有资源。\n",
    "* TensorFlow中几个常见的自动维护的集合：\n",
    "\n",
    "| 集合名称                                 | 集合内容                             | 使用场景                |\n",
    "| :---------------------------------------  |-----------------------------------   | ----------------------  |\n",
    "|  tf.GraphKeys.VARIABLES                  | 所有变量                             | 持久化TensorFlow模型    |\n",
    "| tf.GraphKeys.TRAINABLE_VARIABLES         | 可学习的变量（一般指神经网络中参数） | 模型训练、生成可视化内容|\n",
    "| tf.GraphKeys.SUMMARIES                   | 日志生成相关变量                     | 计算可视化              |\n",
    "| tf.GraphKeys.QUEUE_RUNNERS               | 处理输入的QueueRunner                | 输入处理                |\n",
    "| tf.GraphKeys.MOVING_AVERAGE_VARIABLES    | 所有计算了滑动平均值的变量           | 计算变量的滑动平均值    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF数据模型-张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 张量的概念"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **概念**：张量是对TensorFlow中**计算结果的引用**，并不保存真正的数字，**保存的是**如何得到这些数字的**计算过程**。  \n",
    "* **结构**：名字（name）、维度（shape）、类型（type）  \n",
    "  * **name**:'add_2:0'-节点add_2上的第0个输出  \n",
    "  * **shape**:维度  \n",
    "  * **type**:实数（tf.float32|tf.float64）整数（tf.int8|tf.int16|tf.int32|tf.int64|tf.uint8）布尔型（tf.bool）复数（tf.complex64|tf.complex128）\n",
    "* **运算**：张量运算时，类型要匹配，不然可能出现错误。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.constant([1.0, 2.0], name=\"a\")#  tf.constant是一个计算，得到一个张量，保存在变量a中\n",
    "b = tf.constant([2.0, 3.0], name=\"b\")\n",
    "result = a + b\n",
    "result\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "result.eval()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 张量的使用\n",
    "\n",
    "* 用途一：对中间计算结果的引用 a = tf.constant([1.0, 2.0], name=\"a\")\n",
    "* 用途二：获得及计算结果 tf.Session().run(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF运行模型-会话\n",
    "会话（session）用来执行定义好的运算。管理tensorflow程序运行时的所有资源。tensorflow**不会生成默认会话**，需手动指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()         # 使用一：显示创建会话。\n",
    "sess.run(result)            # 使用会话得到之前计算的结果。\n",
    "sess.close()                # 关闭会话，使得本次运行中使用到的资源可以被释放。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:  # 使用二：上下文管理器来管理会话；解决异常退出的资源释放问题\n",
    "    sess.run(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()         # 使用三：指定默认会话后，通过tf.Tensor.eval()函数来计算张量的值\n",
    "with sess.as_default() as f:\n",
    "     result.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()              # 下面的两个命令有相同的功能。\n",
    "sess.run(result)\n",
    "result.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession ()  # 将自动生成的会话，注册为默认会话。在交互式环境中（python脚本或jupyter）使用方便\n",
    "result.eval()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "配置需要生成的会话 ConfigProto 常用的两个参数：\n",
    "allow_soft_placement=True ：以下任一条件成立时，GPU上运算可以放到CPU上进行：\n",
    "    1、运行无法在GPU上执行\n",
    "    2、没有GPU资源\n",
    "    3、运算输入包含对CPU计算结果的引用\n",
    "log_device_placement=True ：日志中将会记录每个节点被安排在那个设备上以方便调试。生成环境中设为False以减少日志量。\n",
    "'''\n",
    "config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)\n",
    "sess1 = tf.InteractiveSession(config=config)\n",
    "sess2 = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF实现神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF游乐场及神经网络简介\n",
    "\n",
    "http://playground.tensorflow.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 向前传播算法简介\n",
    "![](https://pic1.zhimg.com/80/v2-e2ff929767d1c10f5a2f02e36fb99830_hd.jpg)\n",
    "a = tf.matmul(x, w1)  \n",
    "y = tf.matmul(a, w2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 神经网络参数与TF变量\n",
    "\n",
    "TODO TF随机数生成函数    TF常数生成函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf                                  # 一、三种方法生成TF变量\n",
    "weights = tf.Variable(tf.random_normal([2,3],stddev=2)) # 1.随机数生成变量\n",
    "biases = tf.Variable(tf.zeros([3]))                      # 2.常数生成变量\n",
    "w2 = tf.Variable(weights.initialized_value())            # 3.使用其他变量初始化新的变量\n",
    "w3 = tf.Variable(weights.initialized_value() * 2)\n",
    "'''get_variable()只受variable_scope()影响。variable()受name_scope()和variable_scope()影响；\n",
    "   get_variable()获取指定名称的变量，如果不存在则创建一个，'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('foo') as foo_scope:\n",
    "    v = tf.get_variable('v', [1])\n",
    "with tf.variable_scope(foo_scope, reuse=True):\n",
    "#with tf.variable_scope('foo', reuse=True):\n",
    "    v1 = tf.get_variable('v')\n",
    "v1 == v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf                                  # 二、通过变量实现神经网络的参数和向前传播过程\n",
    "\n",
    "w1= tf.Variable(tf.random_normal([2, 3], stddev=1, seed=1))\n",
    "w2= tf.Variable(tf.random_normal([3, 1], stddev=1, seed=1))\n",
    "x = tf.constant([[0.7, 0.9]])  \n",
    "\n",
    "a = tf.matmul(x, w1)\n",
    "y = tf.matmul(a, w2)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(w1.initializer)   # 初始化 w1\n",
    "sess.run(w2.initializer)   # 初始化 w2 \n",
    "sess.run(y) \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())# 初始化所有变量。\n",
    "w1.assign(w2)                              # 变量赋值；              sess.run(w1.assign(w2))\n",
    "tf.assign(w1,w2)                           # 不同type的赋值会报错\n",
    "tf.assign(w1,w2,validate_shape=False)      # 不同shape的赋值会填充。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 所有变量都会被自动加入到Graph.Keys.VARIABLES 这个集合中。\n",
    "* 通过tf.glabal_variables()函数课可以拿到当前计算图的所有变量。\n",
    "* 变量声明时，trainable参数为True，变量会自动加入到tf.GraphKeys.TRAINABLE_VARIABLES 集合。\n",
    "* tf.trainable_variables()得到所有优化参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 通过TF训练神经网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "w1= tf.Variable(tf.random_normal([2, 3], stddev=1, seed=1))\n",
    "w2= tf.Variable(tf.random_normal([3, 1], stddev=1, seed=1))\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(1, 2), name=\"input\")\n",
    "#x = tf.placeholder(tf.float32, shape=(3, 2), name=\"input\")\n",
    "a = tf.matmul(x, w1)\n",
    "y = tf.matmul(a, w2)\n",
    "\n",
    "sess = tf.Session()\n",
    "init_op = tf.global_variables_initializer()  \n",
    "sess.run(init_op)\n",
    "\n",
    "sess.run(y, feed_dict={x: [[0.7,0.9]]})   # feed_dict字典中需要给出每个用到placeholder的取值。\n",
    "#sess.run(y, feed_dict={x: [[0.7,0.9],[0.1,0.4],[0.5,0.8]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 完整的神经网络样例程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.8113182   1.4845988   0.06532937]\n",
      " [-2.4427042   0.0992484   0.5912243 ]]\n",
      "[[-0.8113182 ]\n",
      " [ 1.4845988 ]\n",
      " [ 0.06532937]]\n",
      "\n",
      "\n",
      "After 0 training step(s), cross entropy on all data is 1.89805\n",
      "After 1000 training step(s), cross entropy on all data is 0.655075\n",
      "After 2000 training step(s), cross entropy on all data is 0.626172\n",
      "After 3000 training step(s), cross entropy on all data is 0.615096\n",
      "After 4000 training step(s), cross entropy on all data is 0.610309\n",
      "\n",
      "\n",
      "[[ 0.02476976  0.56948674  1.6921943 ]\n",
      " [-2.1977348  -0.23668915  1.1143894 ]]\n",
      "[[-0.4554469 ]\n",
      " [ 0.49110925]\n",
      " [-0.9811033 ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from numpy.random import RandomState\n",
    "tf.reset_default_graph()\n",
    "\n",
    "batch_size = 8            # 1. 定义神经网络的参数，输入和输出节点。\n",
    "w1= tf.Variable(tf.random_normal([2, 3], stddev=1, seed=1))\n",
    "w2= tf.Variable(tf.random_normal([3, 1], stddev=1, seed=1))\n",
    "x = tf.placeholder(tf.float32, shape=(None, 2), name=\"x-input\")\n",
    "y_= tf.placeholder(tf.float32, shape=(None, 1), name='y-input')\n",
    "\n",
    "a = tf.matmul(x, w1)      # 2. 定义前向传播过程，损失函数及反向传播算法。\n",
    "y = tf.matmul(a, w2)\n",
    "y = tf.sigmoid(y)\n",
    "cross_entropy = -tf.reduce_mean(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0))\n",
    "                        + (1 - y_) * tf.log(tf.clip_by_value(1 - y, 1e-10, 1.0)))\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)\n",
    "                          #    常用优化：GradientDescentOptimizer|MomentumOptimizer|AdamOptimizer\n",
    "rdm = RandomState(1)      # 3. 生成模拟数据集。\n",
    "X = rdm.rand(128,2)\n",
    "Y = [[int(x1+x2 < 1)] for (x1, x2) in X]\n",
    "\n",
    "with tf.Session() as sess:# 4. 创建一个会话来运行TensorFlow程序。 \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    print(sess.run(w1))    # 输出目前（未经训练）的参数取值。\n",
    "    print(sess.run(w2))\n",
    "    print(\"\\n\")\n",
    "\n",
    "  \n",
    "    STEPS = 5000           # 训练模型。\n",
    "    for i in range(STEPS):\n",
    "        start = (i*batch_size) % 128\n",
    "        end = (i*batch_size) % 128 + batch_size\n",
    "        #sess.run([train_step, y, y_], feed_dict={x: X[start:end], y_: Y[start:end]})\n",
    "        sess.run(train_step, feed_dict={x: X[start:end], y_: Y[start:end]})\n",
    "        if i % 1000 == 0:\n",
    "            total_cross_entropy = sess.run(cross_entropy, feed_dict={x: X, y_: Y}) # 计算张量\n",
    "            print(\"After %d training step(s), cross entropy on all data is %g\" % (i, total_cross_entropy))\n",
    "\n",
    "    print(\"\\n\")            # 输出训练后的参数取值。\n",
    "    print(sess.run(w1))\n",
    "    print(sess.run(w2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn36]",
   "language": "python",
   "name": "conda-env-learn36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "279.273px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
